{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Procesamiento de Lenguaje Natural - CEIA\n",
        "# Desafío 1\n",
        "## Alumno: Hernán Matías Silva"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "### Consigna del desafío 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n",
        "**2**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB.\n",
        "\n",
        "**3**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Documento original (Índice: 10476):\n",
            "This is a general question for US readers:\n",
            "\n",
            "How extensive is the playoff coverage down there?  In Canada, it is almost\n",
            "impossible not to watch a series on TV (ie the only two series I have not had\n",
            "an opportunity to watch this year are Wash-NYI and Chi-Stl, the latter because\n",
            "I'm in the wrong time zone!).  We (in Canada) are basically swamped with \n",
            "coverage, and I wonder how many series/games are televised nationally or even\n",
            "locally in the US and how much precedence they take over, say, local new\n",
            "\n",
            "Clase: rec.sport.hockey\n",
            "================================================================================\n",
            "Documentos más similares:\n",
            "\n",
            "- Documento (Índice: 5064):\n",
            "\n",
            "I only have one comment on this:  You call this a *classic* playoff year\n",
            "and yet you don't include a Chicago-Detroit series.  C'mon, I'm a Boston\n",
            "fan and I even realize that Chicago-Detroit games are THE most exciting\n",
            "games to watch.\n",
            "  Clase: rec.sport.hockey\n",
            "----------------------------------------\n",
            "- Documento (Índice: 1988):\n",
            "OK, I'll join in the fun and give my playoff predictions: \n",
            "\n",
            "1st round: \n",
            "----------\n",
            "\n",
            "PITT vs NYI:  PITT in 4.  \n",
            "WASH vs NJD:  WASH in 6. \n",
            "\n",
            "BOS  vs BUF:  BOS  in 5. \n",
            "QUE  vs MON:  MON  in 7. \n",
            "\n",
            "CHI  vs STL:  CHI in 4. \n",
            "DET  vs TOR:  DET in 6. \n",
            "\n",
            "VAN  vs WIN:  WIN in 6. \n",
            "CAL  vs  LA:  CAL in 5. \n",
            "\n",
            "2nd round: \n",
            "----------\n",
            "\n",
            "PITT vs WASH: PITT in 4. \n",
            "BOS  vs MON:  BOS  in 6. \n",
            "\n",
            "CHI  vs DET:  CHI  in 7. \n",
            "WIN  vs CAL:  CAL  in 5. \n",
            "\n",
            "3rd round: \n",
            "----------\n",
            "\n",
            "PITT vs BOS:  PITT in 5. \n",
            "CHI  vs CAL:  CHI  in 5. \n",
            "\n",
            "\n",
            "  Clase: rec.sport.hockey\n",
            "----------------------------------------\n",
            "- Documento (Índice: 7195):\n",
            "1st round: \n",
            "----------\n",
            "\n",
            "PITT vs NYI:  PITT in 4. \n",
            "\n",
            "It looks like a safe bet.  NYI has been bagging it of late.\n",
            "NYI and NJD have a showdown Friday night for the honour\n",
            "of Pittsburg anyway.  Pigsburg in 4.\n",
            "\n",
            "WASH vs NJD:  WASH in 6. \n",
            "I think that NJD have a solid team and will compete with\n",
            "WASH.  I agree though with WASH in 6.\n",
            "\n",
            "BOS  vs BUF:  BOS  in 5. \n",
            "The B's have been playing awesome hockey in the last\n",
            "two weeks.  The only question is how long will it last?\n",
            "Fuhr is a dud.  BOS in 4.\n",
            "\n",
            "QUE  vs MON\n",
            "  Clase: rec.sport.hockey\n",
            "----------------------------------------\n",
            "- Documento (Índice: 3625):\n",
            "Well here it goes...my crazy predictions (which never come true, but hey..)\n",
            "\n",
            "Adams\n",
            "\tBos vs. Buf - Bos in 5 (cakewalk for the hot Bruins)\n",
            "\tQue vs. Mon - Que in 6 (best series of the first round)\n",
            "\n",
            "Patrick\n",
            "\tPit vs. NYI - Pit in 5 (NYI wins fourth game)\n",
            "\tWas vs. NJD - NJD in 7 (a grueling upset, possibly OT in game 7)\n",
            "\n",
            "Norris\n",
            "\tChi vs. StL - Chi in 5 (StL is no match for Keenan's Krew)\n",
            "\tDet vs. Tor - Tor in 6 (Clark steps it up in playoffs this year)\n",
            "\n",
            "Smythe (who cares?)\n",
            "\tVan vs. Win - Win in 7 (so I\n",
            "  Clase: rec.sport.hockey\n",
            "----------------------------------------\n",
            "- Documento (Índice: 7952):\n",
            "\n",
            "Probably because everyone (that is, everyone who has cable) can watch\n",
            "every Braves game. They are the only team that has all of its games\n",
            "broadcast nationwide. And if you don't like your local team, or you don't\n",
            "have a local team, the Braves can kind of become your local team because\n",
            "you can watch them every day.\n",
            "\n",
            "\n",
            "--I'm outta here like Vladimir!\n",
            "-Alan\n",
            "  Clase: rec.sport.baseball\n",
            "----------------------------------------\n",
            "================================================================================\n",
            "Documento original (Índice: 1824):\n",
            "\n",
            "\n",
            "\tI think this kind of comparison is pretty useless in general.  The\n",
            "processor is only good when a good computer is designed around it adn the\n",
            "computer is used in its designed purpose.  Comparing processor speed is\n",
            "pretty dumb because all you have to do is just increase the clock speed\n",
            "to increase speed among other things.\n",
            "\n",
            "\tI mean how can you say a 040 is faster than a 486 without \n",
            "giving is operational conditions?  Can you say the same when \n",
            "you are running a program that uses a lot of transi\n",
            "\n",
            "Clase: comp.sys.mac.hardware\n",
            "================================================================================\n",
            "Documentos más similares:\n",
            "\n",
            "- Documento (Índice: 5509):\n",
            "rvenkate@ux4.cso.uiuc.edu (Ravikuma Venkateswar) writes ...\n",
            "\n",
            "Benchmarks are for marketing dweebs and CPU envy.  OK, if it will make\n",
            "you happy, the 486 is faster than the 040.  BFD.  Both architectures\n",
            "are nearing then end of their lifetimes.  And especially with the x86\n",
            "architecture: good riddance.\n",
            "\n",
            "\n",
            "The point being the processor speed is only one of many aspects of a\n",
            "computers performance.  Clock speed, processor, memory speed, CPU\n",
            "architecture, I/O systems, even the application program all con\n",
            "  Clase: comp.sys.mac.hardware\n",
            "----------------------------------------\n",
            "- Documento (Índice: 9921):\n",
            "dhk@ubbpc.uucp (Dave Kitabjian) writes ...\n",
            "\n",
            "040 486 030 386 020 286\n",
            "\n",
            "\n",
            "060 fastest, then Pentium, with the first versions of the PowerPC\n",
            "somewhere in the vicinity.\n",
            "\n",
            "\n",
            "No.  Computer speed is only partly dependent of processor/clock speed.\n",
            "Memory system speed play a large role as does video system speed and\n",
            "I/O speed.  As processor clock rates go up, the speed of the memory\n",
            "system becomes the greatest factor in the overall system speed.  If\n",
            "you have a 50MHz processor, it can be reading another word \n",
            "  Clase: comp.sys.mac.hardware\n",
            "----------------------------------------\n",
            "- Documento (Índice: 305):\n",
            "I believe it goes or will go:\n",
            "680060\n",
            "powerPC\n",
            "Pentium\n",
            "680040\n",
            "486\n",
            "680030\n",
            "386\n",
            "680020\n",
            "286=680000\n",
            "\n",
            "In a resent article in one of the macMags I think a 50mHz 030 accelerator was\n",
            " slightly slower than a 25mHz 040 accel. But, this is using a system designed\n",
            " for the 030. So, It stands to reason that a system designed for an 040 ie\n",
            " quadra) would do better. So overall I'd figure 040 = 030 * 2.5 or so.\n",
            "    Along the same lines the new POwerPC stuff is supposed to run the system\n",
            " at the level of a fast qua\n",
            "  Clase: comp.sys.mac.hardware\n",
            "----------------------------------------\n",
            "- Documento (Índice: 6364):\n",
            "Well folks, after some thought the answer struck me flat in the face:\n",
            "\n",
            "\"Why would Apple release a Duo Dock with a processor of its own?\"\n",
            "\n",
            "Here's why- People have hounded Apple for a notebook with a 68040 processor\n",
            "in it. Apple can't deliver that right now because the 040 saps too much\n",
            "power, radiates far too much heat, and is too large for a notebook. How\n",
            "does one get around that without designing a new chipset? Use existing\n",
            "PowerBook technology to your best advantage. The Duo Dock gives Apple a\n",
            "  Clase: comp.sys.mac.hardware\n",
            "----------------------------------------\n",
            "- Documento (Índice: 4359):\n",
            "If you get the Centris 650 with CD configuration, you are getting a Mac with\n",
            "a 68RC040 processor that has built-in math coprocessor support.  My \n",
            "understanding is that the \"optional fpu\" refers to your option of purchasing\n",
            "the Centris 650 4/80 without FPU OR one of the other configurations WITH FPU.\n",
            "\n",
            "Apple does not offer an upgrade from the non-FPU system to become an FPU\n",
            "system.  And, it is unclear whether the '040 processor on the non-FPU system\n",
            "(a 68LC040) can be replaced with a 68RC040 suppl\n",
            "  Clase: comp.sys.mac.hardware\n",
            "----------------------------------------\n",
            "================================================================================\n",
            "Documento original (Índice: 409):\n",
            "I can't fiqure this out.  I have properly compiled pov on a unix machine\n",
            "running SunOS 4.1.3  The problem is that when I run the sample .pov files and\n",
            "use the EXACT same parameters when compiling different .tga outputs.  Some\n",
            "of the .tga's are okay, and other's are unrecognizable by any software.\n",
            "\n",
            "Clase: comp.graphics\n",
            "================================================================================\n",
            "Documentos más similares:\n",
            "\n",
            "- Documento (Índice: 3444):\n",
            "Hi, I'm just getting into PoVRay and I was wondering if there is a graphic\n",
            "package that outputs .POV files.  Any help would be appreciated.\n",
            "Thanks.\n",
            "\n",
            "Later'ish\n",
            "Craig\n",
            "\n",
            "  Clase: comp.graphics\n",
            "----------------------------------------\n",
            "- Documento (Índice: 5905):\n",
            "\n",
            "Hallo POV-Renderers !\n",
            "I've got a BocaX3 Card. Now I try to get POV displaying True Colors\n",
            "while rendering. I've tried most of the options and UNIVESA-Driver\n",
            "but what happens isn't correct.\n",
            "Can anybody help me ?\n",
            "\n",
            "  Clase: comp.graphics\n",
            "----------------------------------------\n",
            "- Documento (Índice: 5405):\n",
            "Has anybody made a converter from irit's .irt or .dat format to\n",
            " .pov format ?\n",
            "\n",
            "Thanks!\n",
            "\n",
            "  Clase: comp.graphics\n",
            "----------------------------------------\n",
            "- Documento (Índice: 1764):\n",
            "hi guys\n",
            " like all people in this group i'm a fans of fractal and render sw\n",
            " my favourite are fractint pov & 3dstudio 2.0 \n",
            " now listen my ideas\n",
            " i'have just starting now to be able to use 3dstudio quite well\n",
            " so i'm simulating a full animation of a f1 grand prix\n",
            " unfortanatly just some lap(10?)\n",
            " i' m very interested about all kind of .prj .3ds and so on\n",
            " concerning about cars or parts of its (motors wheel ...)\n",
            " (dxf are good enough)\n",
            " does anyone have object to give me to complete my hard animatio\n",
            "  Clase: comp.graphics\n",
            "----------------------------------------\n",
            "- Documento (Índice: 6117):\n",
            "\n",
            "\n",
            "\n",
            "Or use a SunOS 4.1.1 ld.\n",
            "  Clase: comp.windows.x\n",
            "----------------------------------------\n",
            "================================================================================\n",
            "Documento original (Índice: 4506):\n",
            "\n",
            "This does sound good, but I heard it tends to leave more grit, etc in the \n",
            "oil pan.  Also, I've been told to change the old when it's hot before the\n",
            "grit has much time to settle.\n",
            "\n",
            "Any opinions?\n",
            "\n",
            "\n",
            "Clase: rec.autos\n",
            "================================================================================\n",
            "Documentos más similares:\n",
            "\n",
            "- Documento (Índice: 5691):\n",
            "\n",
            "you can say that again.\n",
            "how does $23 for a new thermostat sound?\n",
            "  Clase: rec.autos\n",
            "----------------------------------------\n",
            "- Documento (Índice: 4211):\n",
            "\n",
            "\n",
            "It's normal for the BMW K bikes to use a little oil in the first few thousand \n",
            "miles.  I don't know why.  I've had three new K bikes, and all three used a\n",
            "bit of oil when new - max maybe .4 quart in first 1000 miles; this soon quits\n",
            "and by the time I had 10,000 miles on them the oil consumption was about zero.\n",
            "I've been told that the harder you run the bike (within reason) the sooner\n",
            "it stops using any oil.\n",
            "\n",
            "  Clase: rec.motorcycles\n",
            "----------------------------------------\n",
            "- Documento (Índice: 2971):\n",
            "\n",
            "[Long silly discussion deleted...]\n",
            "\n",
            "\n",
            "This suggestion isn't as far-fetched as it sounds.  Years ago in another\n",
            "time and place, I used to do oil changes in boats powered by automotive\n",
            "engines.  In many cases, there was no way to get any sort of a tray under\n",
            "the oil pan because it was boxed in by the bottom of the hull and various\n",
            "floation chambers on each side.  And if you *did* get something there, you'd\n",
            "spill all the oil out of it for sure trying to get it back out again.\n",
            "\n",
            "So we used a small pu\n",
            "  Clase: rec.autos\n",
            "----------------------------------------\n",
            "- Documento (Índice: 7425):\n",
            "\n",
            "Oh come on, Silly, all you have to do is cut a hole in your hood and \n",
            "put a tube there so you can get to the oil fill hole.  What do you\n",
            "think all those big air intake things are for on those hot-rod cars?\n",
            "They're just for looks only...little does anyone know, they provide\n",
            "access to the oil-fill hole.\n",
            "  Clase: rec.autos\n",
            "----------------------------------------\n",
            "- Documento (Índice: 9491):\n",
            "My friend brought a subaru SVX recently.  I had drove it for couples times and I\n",
            "think its a great car, esp on snow.  However when she took it to a local Subaru\n",
            "dealer for a oil change, the bill came out to be about 80 dollars.  The dealer\n",
            "told us it is because to change the oil filter on a SVX it is necessary to\n",
            "disassemble a metal cover under the engine and that took an hour of labour.\n",
            "At first, we think we are being ripped off so she phone to a dealer in Toronto\n",
            "but found out the they are cha\n",
            "  Clase: rec.autos\n",
            "----------------------------------------\n",
            "================================================================================\n",
            "Documento original (Índice: 4012):\n",
            "For those Leaf fans who are concerned, the following players are slated for\n",
            "return on Thursday's Winnipeg-Toronto game :\n",
            "    Peter Zezel, John Cullen\n",
            "\n",
            "  Mark Osborne and Dave Ellett are questionable to return on Thursday.\n",
            "\n",
            "Clase: rec.sport.hockey\n",
            "================================================================================\n",
            "Documentos más similares:\n",
            "\n",
            "- Documento (Índice: 6718):\n",
            "\n",
            "  I thought that he was comparing Cullen to TEEMU SEL[NNE. I always thought\n",
            "  that salami is some sort of sausage, BUT IF YOU, dear Roger, ARE ABLE TO\n",
            "  SEE SALAMI ON THE ICE PLAYING HOCKEY... I don't know what to do, but you\n",
            "  surely should do something and very quickly!!!\n",
            "\n",
            "  Maybe you think that if you keep on talking some rubbish, after some time\n",
            "  everybody will consider it to be really true... You should take care of\n",
            "  your LEAFS, they surely need it more.\n",
            "  \n",
            "\n",
            "  At least we have seen him p\n",
            "  Clase: rec.sport.hockey\n",
            "----------------------------------------\n",
            "- Documento (Índice: 10644):\n",
            "In  <1qvos8$r78@cl.msu.>, vergolin@euler.lbs.msu.edu (David Vergolini) writes...\n",
            "\n",
            "There's quite a few Wings fans lurking about here, they just tend\n",
            "to be low key and thoughtful rather than woofers.  I suppose every\n",
            "family must have a Roger Clinton, though.  But remember (to paraphrase\n",
            "one of my favorite Star Trek lines), \"if we adopt the ways of the Leaf\n",
            "fans, we are as bad as the Leaf fans\".\n",
            "\n",
            "Ron\n",
            "  Clase: rec.sport.hockey\n",
            "----------------------------------------\n",
            "- Documento (Índice: 2677):\n",
            "\n",
            "But I gotta tell ya,\n",
            "\n",
            "If the Hawks can't beat the Blues in a game that\n",
            "IS significant I can't wait to see how the Blues\n",
            "might do against Toronto ;)\n",
            "\n",
            "BTW, if you think that the Hawks deserved to win that game\n",
            "I think you were not watching the same one everyone else\n",
            "was.\n",
            "\n",
            "ROAR'IN LEAF FAN\n",
            "  Clase: rec.sport.hockey\n",
            "----------------------------------------\n",
            "- Documento (Índice: 8096):\n",
            "\n",
            "\n",
            "Implicitly you are assuming that goals scored against Winnipeg with Selanne\n",
            "on the ice can be blamed on him...Roger, he is a FORWARD.  Winnipeg has a\n",
            "lousy defensive record anyway.  Let's put it another way.  John Cullen's +/-\n",
            "is terrible.  What's your excuse for him?  That his powerplay points don't\n",
            "count?  Neither do Selanne's... \n",
            "\n",
            "\n",
            "Knowledgeable hockey observers the world over would agree that\n",
            "feeding Selanne so he can score does contribute in a meaningful way to\n",
            "winning. \n",
            "\n",
            "\n",
            "You're worried \n",
            "  Clase: rec.sport.hockey\n",
            "----------------------------------------\n",
            "- Documento (Índice: 7071):\n",
            "Dave Kingman is Jewish\n",
            "  Clase: rec.sport.baseball\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Cargar los datos\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Instanciar y ajustar el vectorizador\n",
        "tfidfvect = TfidfVectorizer(\n",
        "    stop_words='english',   # Eliminar las palabras comunes del inglés\n",
        "    max_df=0.8,             # Elminiar los términos que aparecen en más del 80% de los documentos\n",
        "    min_df=3,               # Eliminar los términos que aparecen en menos de 3 documentos\n",
        "    ngram_range=(1, 2),     # Considerar unigramas y bigramas \n",
        "    max_features=10000,     # Limitar el número de características a las 10000 más relevantes\n",
        "    sublinear_tf=True       # Aplicar una escala sublineal a los términos\n",
        ")\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "y_train = newsgroups_train.target\n",
        "\n",
        "# Semilla \n",
        "random.seed(42)\n",
        "\n",
        "# Seleccionar índices de 5 documentos al azar\n",
        "cant_doc = X_train.shape[0]\n",
        "doc_indices = random.sample(range(cant_doc), 5)\n",
        "\n",
        "# Iterar sobre cada documento seleccionado\n",
        "for idx in doc_indices:\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Documento original (Índice: {idx}):\")\n",
        "    print(newsgroups_train.data[idx][:500])  # Mostrar solo los primeros 500 caracteres\n",
        "    print(f\"\\nClase: {newsgroups_train.target_names[y_train[idx]]}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Calcular similitud coseno con todos los documentos\n",
        "    cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
        "    \n",
        "    # Obtener los índices de los 5 documentos más similares (excluyendo el propio documento)\n",
        "    most_similar_indices = np.argsort(cossim)[::-1][1:6]\n",
        "    \n",
        "    print(\"Documentos más similares:\\n\")\n",
        "    for sim_idx in most_similar_indices:\n",
        "        print(f\"- Documento (Índice: {sim_idx}):\")\n",
        "        print(newsgroups_train.data[sim_idx][:500])  # Mostrar solo los primeros 500 caracteres\n",
        "        print(f\"  Clase: {newsgroups_train.target_names[y_train[sim_idx]]}\")\n",
        "        print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Para el documento 10476 de la clase rec.sport.hockey que habla sobre la cobertura de los playoff, los primeros 4 documentos son de la misma clase que el original y hablan de los playoff, 3 de ellos de predicciones de juegos. El último documento a pesar de ser de otra clase rec.sport.baseball tiene similitud con el original ya que habla de la cobertura de un equipo. \n",
        "2. Para el documento 1824 de la clase comp.sys.mac.hardware que habla sobre la comparación del rendimiento de computadoras, los 5 documentos corresponden a la misma clase y los 3 primeros también hablan del mismo tema muy similares al original. Los últimos dos comentan sobre el hardware de computadoras.\n",
        "3. Para el documento 409 de la clase comp.graphics que comenta sobre un problema con archivos .pov al compilar una aplicación, los primeros 4 documentos son de la misma clase y tres de ellos comentan de archivos el cuarto mensiona la sigla POV. El último documento  es de la clase comp.windows.x solo mensiona SunOS igual que el documento original.\n",
        "4. Para el documento 4506 de la clase rec.autos que consulta sobre el cartel de aceite del motor. Hay 4 documentos de la misma clase que el original y otro de rec.motorcycles. Cuatro documentos hablan del aceite en el motor. Un documento sólo concuerda con el original en la palabra \"sound\", que es un verbo intransitivo en este caso, pero habla de un tema distinto.\n",
        "5. Para el documento 4012 de la clase rec.sport.hockey que habla sobre jugadores de un equipo Leafs de hockey. Hay 5 documentos de la misma clase que el original, 4 nombran al equipo Leafs y uno a Winnipeg que también se nombra en el original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor F1-score macro: 0.7532505558566581\n",
            "Mejores parámetros: {'model': 'ComplementNB', 'alpha': 0.5, 'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 2), 'max_features': None, 'sublinear_tf': True}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargar datos y dividir en train y test\n",
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "X, y = newsgroups.data, newsgroups.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definir rangos de hiperparámetros para el vectorizador y los modelos\n",
        "vectorizer_params = {\n",
        "    \"max_df\": [0.8, 0.9],\n",
        "    \"min_df\": [3, 5],\n",
        "    \"ngram_range\": [(1, 1), (1, 2)],\n",
        "    \"max_features\": [5000, 10000, None],\n",
        "    \"sublinear_tf\": [True, False],\n",
        "    \"stop_words\": ['english']\n",
        "}\n",
        "\n",
        "model_params = {\n",
        "    \"alpha\": [0.5, 1.0, 2.0]\n",
        "}\n",
        "\n",
        "best_f1_score = 0\n",
        "best_params = {}\n",
        "\n",
        "# Exploración de hiperparámetros\n",
        "for max_df in vectorizer_params[\"max_df\"]:\n",
        "    for min_df in vectorizer_params[\"min_df\"]:\n",
        "        for ngram_range in vectorizer_params[\"ngram_range\"]:\n",
        "            for max_features in vectorizer_params[\"max_features\"]:\n",
        "                for sublinear_tf in vectorizer_params[\"sublinear_tf\"]:\n",
        "                    # Configurar y ajustar el vectorizador\n",
        "                    tfidfvect = TfidfVectorizer(\n",
        "                        stop_words='english',\n",
        "                        max_df=max_df,\n",
        "                        min_df=min_df,\n",
        "                        ngram_range=ngram_range,\n",
        "                        max_features=max_features,\n",
        "                        sublinear_tf=sublinear_tf\n",
        "                    )\n",
        "                    X_train_vect = tfidfvect.fit_transform(X_train)\n",
        "                    X_test_vect = tfidfvect.transform(X_test)\n",
        "\n",
        "                    # Probar MultinomialNB y ComplementNB con diferentes alphas\n",
        "                    for alpha in model_params[\"alpha\"]:\n",
        "                        for model_type in [MultinomialNB, ComplementNB]:\n",
        "                            clf = model_type(alpha=alpha)\n",
        "                            clf.fit(X_train_vect, y_train)\n",
        "                            y_pred = clf.predict(X_test_vect)\n",
        "\n",
        "                            # Calcular el F1-score macro\n",
        "                            f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "                            # Guardar mejores resultados\n",
        "                            if f1_macro > best_f1_score:\n",
        "                                best_f1_score = f1_macro\n",
        "                                best_params = {\n",
        "                                    \"model\": model_type.__name__,\n",
        "                                    \"alpha\": alpha,\n",
        "                                    \"max_df\": max_df,\n",
        "                                    \"min_df\": min_df,\n",
        "                                    \"ngram_range\": ngram_range,\n",
        "                                    \"max_features\": max_features,\n",
        "                                    \"sublinear_tf\": sublinear_tf\n",
        "                                }\n",
        "\n",
        "# Imprimir los mejores resultados\n",
        "print(\"Mejor F1-score macro:\", best_f1_score)\n",
        "print(\"Mejores parámetros:\", best_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Palabra: computer\n",
            "================================================================================\n",
            "Palabras más similares:\n",
            "- science (similitud: 0.1297)\n",
            "- graphics (similitud: 0.1297)\n",
            "- computers (similitud: 0.1250)\n",
            "- software (similitud: 0.1148)\n",
            "- university (similitud: 0.1071)\n",
            "================================================================================\n",
            "Palabra: science\n",
            "================================================================================\n",
            "Palabras más similares:\n",
            "- scientific (similitud: 0.2408)\n",
            "- scientists (similitud: 0.1961)\n",
            "- computer (similitud: 0.1297)\n",
            "- university (similitud: 0.1291)\n",
            "- psychology (similitud: 0.1202)\n",
            "================================================================================\n",
            "Palabra: software\n",
            "================================================================================\n",
            "Palabras más similares:\n",
            "- hardware (similitud: 0.1881)\n",
            "- pc (similitud: 0.1438)\n",
            "- packages (similitud: 0.1269)\n",
            "- modem (similitud: 0.1164)\n",
            "- disk (similitud: 0.1155)\n",
            "La palabra 'system' no está en el vocabulario.\n",
            "================================================================================\n",
            "Palabra: data\n",
            "================================================================================\n",
            "Palabras más similares:\n",
            "- transfer (similitud: 0.1544)\n",
            "- encrypted (similitud: 0.1215)\n",
            "- use (similitud: 0.1161)\n",
            "- bus (similitud: 0.1149)\n",
            "- rate (similitud: 0.1010)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Cargar los datos\n",
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "X, y = newsgroups.data, newsgroups.target\n",
        "\n",
        "# Configurar y ajustar el vectorizador\n",
        "tfidfvect = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    max_df=0.8,\n",
        "    min_df=5,\n",
        "    ngram_range=(1, 1),  # Unigramas para palabras individuales\n",
        "    max_features=5000,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "X_tfidf = tfidfvect.fit_transform(X)\n",
        "\n",
        "# Transponer la matriz documento-término\n",
        "X_terms_docs = X_tfidf.T\n",
        "\n",
        "# Obtener lista de términos\n",
        "terms = tfidfvect.get_feature_names_out()\n",
        "\n",
        "# Seleccionar palabras manualmente\n",
        "selected_words = [\"computer\", \"science\", \"software\", \"system\", \"data\"]\n",
        "\n",
        "# Iterar sobre las palabras seleccionadas\n",
        "for word in selected_words:\n",
        "    if word in terms:\n",
        "        word_idx = np.where(terms == word)[0][0]\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"Palabra: {word}\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # Calcular similitud coseno con otras palabras\n",
        "        word_vector = X_terms_docs[word_idx]\n",
        "        cossim = cosine_similarity(word_vector, X_terms_docs)[0]\n",
        "\n",
        "        # Obtener índices de las 5 palabras más similares (excluyendo la palabra misma)\n",
        "        most_similar_indices = np.argsort(cossim)[::-1][1:6]\n",
        "\n",
        "        print(\"Palabras más similares:\")\n",
        "        for sim_idx in most_similar_indices:\n",
        "            similar_word = terms[sim_idx]\n",
        "            similarity_score = cossim[sim_idx]\n",
        "            print(f\"- {similar_word} (similitud: {similarity_score:.4f})\")\n",
        "    else:\n",
        "        print(f\"La palabra '{word}' no está en el vocabulario.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
